{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "author_list = ['Charles Dickens','Jane Austen','Sir Arthur Conan Doyle','George Eliot','Jules Verne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "L = 40# length of sentences to be extracted - L\n",
    "N = 1000 # number of records for a book - N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13632/2349009362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mauthor_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbook_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Data/{author}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbook_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "sentances = pd.DataFrame()\n",
    "\n",
    "for author in author_list:\n",
    "    for book_name in os.listdir(f\"Data/{author}\"):\n",
    "        if book_name.endswith(\".txt\"):\n",
    "            file_path = (f\"Data/{author}/{book_name}\")\n",
    "            \n",
    "            data = open(file_path,'r',encoding=\"mbcs\").read()\n",
    "            data = re.sub('\\[.*?\\]','',data)\n",
    "            data = re.sub('[%s]' % re.escape(string.punctuation),'',data)#remove punctuation marks\n",
    "            data = re.sub('\\w*\\d\\w*','',data)#remove numbers\n",
    "            data = re.sub('[^a-zA-Z\\d\\s.]','',data)\n",
    "            data = \" \".join(data.split())\n",
    "#             print(\"before:\" ,len(data))\n",
    "            \n",
    "            tagged_sentence = nltk.tag.pos_tag(data.split())\n",
    "            edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
    "            paragraph = (' '.join(edited_sentence)).lower()\n",
    "#             print(\"After:\" ,len(paragraph))\n",
    "            \n",
    "            sentence_full =\"\"\n",
    "        \n",
    "            for sentence_read in paragraph:\n",
    "                sentence_full += sentence_read\n",
    "\n",
    "            words = sentence_full.split()\n",
    "            subs = []\n",
    "            for i in range(0, len(words), L):\n",
    "                subs.append(\" \".join(words[i:i+L]))\n",
    "\n",
    "            data_temp = pd.DataFrame(subs, columns=['text'])\n",
    "            data_temp[\"author\"] = author\n",
    "            data_temp[\"book\"] = book_name\n",
    "            data_temp[\"length\"] = data_temp[\"text\"].str.len()\n",
    "\n",
    "            data_temp = data_temp.sample(N, replace=True)\n",
    "\n",
    "            print(\"Author:\" + author + \" Book:\" + str(book_name) +\" Total records:\" + str(len(subs)) + \" -> Extracted:\" + str(len(data_temp)))        \n",
    "\n",
    "            sentances = pd.concat([sentances, data_temp], ignore_index=True)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was not his son why did he go the one occupati...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>Bleak House.txt</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>little things lie here said adjusting them wit...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>Bleak House.txt</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hearty the clerk having now again gone in to s...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>Bleak House.txt</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i could not define but now all at once a somet...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>Bleak House.txt</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ideas of delivering himself up to justice and ...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>Bleak House.txt</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           author  \\\n",
       "0  was not his son why did he go the one occupati...  Charles Dickens   \n",
       "1  little things lie here said adjusting them wit...  Charles Dickens   \n",
       "2  hearty the clerk having now again gone in to s...  Charles Dickens   \n",
       "3  i could not define but now all at once a somet...  Charles Dickens   \n",
       "4  ideas of delivering himself up to justice and ...  Charles Dickens   \n",
       "\n",
       "              book  length  \n",
       "0  Bleak House.txt     212  \n",
       "1  Bleak House.txt     226  \n",
       "2  Bleak House.txt     207  \n",
       "3  Bleak House.txt     204  \n",
       "4  Bleak House.txt     220  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_dataset = sentances[['author', 'text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_dataset.to_csv(\"dataset_01.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entities = []\n",
    "#             labels = []\n",
    "            \n",
    "#             sentences = nltk.sent_tokenize(data)\n",
    "#             for sent in sentences:\n",
    "#                 for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)),binary=False):\n",
    "#                     if hasattr (chunk,'label'):\n",
    "#                         entities.append(''.join(c[0] for c in chunk))\n",
    "#                         labels.append(chunk.label())\n",
    "                        \n",
    "#             entities_labels= list(set(zip(entities,labels)))\n",
    "#             entities_df=pd.DataFrame(entities_labels)\n",
    "#             entities_df.columns = [\"En\",\"Lab\"]\n",
    "#             entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
